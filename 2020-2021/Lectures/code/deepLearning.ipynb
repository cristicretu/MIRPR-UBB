{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Lecture 4: Deep learning\n",
    "\n",
    "## 4.1. Deep learning - main elements\n",
    "\n",
    "### 4.1.1. Concept\n",
    "\n",
    "What is it?\n",
    "- methodology in which we can train machine complex representations\n",
    "- addresses the problem of learning hierarchical representations with a single (a few) algorithm(s)\n",
    "- models with a feature hierarchy (lower-level features are learned at one layer of a model, and then those features are combined at the next level). \n",
    "- it's deep if it has more than one stage of non-linear feature transformation\n",
    "- hierarchy of representations with increasing level of abstraction \n",
    "    * Image recognition \n",
    "        - Pixel → edge → texton → motif → part → object \n",
    "    * Text \n",
    "        - Character → word → word group → clause → sentence → story \n",
    "    * Speech \n",
    "        - Sample → spectral band → sound → … → phone → phoneme → word\n",
    "\n",
    "Deep networks/architectures\n",
    "- Convolutional NNs\n",
    "- Auto-encoders\n",
    "- Deep Belief Nets (Restricted Boltzmann machines)\n",
    "- Recurrent Neural Networks \n",
    "- Generative Adversial Networks\n",
    "\n",
    "\n",
    "Main characteristics:\n",
    "- Collection of methods to improve the optimisation and generalisation of learning methods, especially NNs:\n",
    "    * Rectified linear units\n",
    "    * Dropout\n",
    "    * Batch normalisation\n",
    "    * Weight decay regularisation\n",
    "    * Momentum learning\n",
    "\n",
    "- Stacking layers of transformations to create successively more abstract levels of representation\n",
    "    * Depth over breadth\n",
    "    * Deep MLPs\n",
    "\n",
    "- Shared parameters\n",
    "    * Convolutional NNs\n",
    "    * Recurrent NNs\n",
    "\n",
    "- Technological improvements\n",
    "    * Massively parallel processing: GPUs, CUDA\n",
    "    * Fast libraries: Torch, cuDNN, CUDA-convNet, Theano\n",
    "\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "\n",
    "### 4.1.2. An ML algorithm as an optimisation approach \n",
    "\n",
    "An optimization problem     \n",
    "- minimize the loss function \n",
    "- with respect to the parameters of the score function.\n",
    "\n",
    "Reamrk:\n",
    "- score function  \n",
    "    * maps the raw data to class scores/labels\n",
    "- loss function \n",
    "    * quantifies the agreement between the predicted scores and the ground truth scores/labels\n",
    "    * ANN: quantifies the quality of any particular set of weights W\n",
    "    * two components\n",
    "        - the data loss computes the compatibility between the computed scores and the true labels. \n",
    "        - the regularization loss is only a function of the weights\n",
    "\n",
    "Suppose a supervised classification problem\n",
    "- Some input data (examples, instances, cases)\n",
    "    * Training data – as pairs (attributeData_i, label_i), where:\n",
    "        - i = 1, N (N = \\# of training data)\n",
    "        - $attributeData_i= (atri_1, atri_2, ..., atri_m)$, m – \\# attributes (characteristics, features) for an input data\n",
    "        - $label_i ϵ \\{Label_1, Label_2, …, Label_{\\#classes}\\}$\n",
    "    * Test data – as ($attributeData_i$), i = 1, n (n = \\# of testing data).\n",
    "- Determine\n",
    "    * an unknown function that maps inputs (features) into outputs (labels)\n",
    "    * output (label / class / value / score) associated to a new data by using the learnt function\n",
    "\n",
    "Quality of learning\n",
    "- Accuracy / Precision / Recall / etc\n",
    "    * does not reflect the learnt decision model\n",
    "- A loss function \n",
    "    * Expresses (encodes) the learnt model \n",
    "    * Difference between desired (D) and computed (C) output\n",
    "    * L2 norm - Quadratic cost (mean squared error) \n",
    "    > $ \\sum{|| D – C||^2}$  \n",
    "    * L1 norm \n",
    "    > $ \\sum{| D – C|} $\n",
    "    * SVM loss (hinge loss, max-margin loss) \n",
    "    > $ \\sum_{i}{\\sum_{j, j ≠ y_i}{max(C_j – D_{y_i} + \\Delta, 0)}}$\n",
    "    * Softmax loss \n",
    "    > $ \\sum_{i}{\\frac{- ln(exp(D_{y_i}))}{\\sum_{j, j ≠ y_i}{exp(C_j)}}}$\n",
    "    * Cross-entropy \n",
    "    > $-\\sum{\\frac{D ln C + ( 1 – D) ln(1 - C)}{n}}$ \n",
    "\n",
    "Several important mappings\n",
    "- Constant f(x) = c\n",
    "- Step f(x) = a, if x < theta, and b, otherwise  \n",
    "- Linear f(x) = a x + b\n",
    "- Sigmoid σ(x) = 1 / (1 + e^{−x}) (avoid it in a Conv NN)\n",
    "- Hyperbolic tangent function tanh(x) = 2 σ(2x) − 1\n",
    "- Rectified linear neuron/unit (ReLU) f(x) = max(0, x)\n",
    "- Leak ReLU (Parametric rectifier) f(x) = max(α x, x)\n",
    "- Maxout max(w^T_1x + b_1,w^T_2x + b_2)\n",
    "- Exponential linear units (ELU)  f(x) = x, if x > 0 and α (exp(x) – 1), if x ≤ 0\n",
    "\n",
    "\n",
    "A linear classifier\n",
    "\n",
    "> $f(x, w) = w · x + b$\n",
    "\n",
    "  >> $w \\in R^{\\#classes \\times \\#features}$ \n",
    "\n",
    "  >> $x \\in R^{\\#features \\times 1}$\n",
    "\n",
    "  >> $b \\in R^{\\#classes}$\n",
    "\n",
    "A non linear classifier \n",
    "\n",
    "> $f(x, w) = w_2 max(0, w_1 · x + b_1) + b_2$,\n",
    "    \n",
    "  >> $w_1 \\in R^{PARAM \\times \\#features}$ \n",
    "  \n",
    "  >> $x \\in R^{\\#features \\times 1}$\n",
    "  \n",
    "  >> $b_1 \\in R^{PARAM}$\n",
    "  \n",
    "  >> $w_2 \\in R${\\#classes \\times PARAM}$\n",
    "  \n",
    "  >> $b_2 \\in R^{\\#classes}$\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "**Classical ANN**\n",
    "\n",
    "Architectures – special graphs with nodes placed on layers \n",
    "- Layers \n",
    "    * Input layer – size = input’s size (#features)\n",
    "    * Hidden layers – various sizes (#layers, # neurons/layer)\n",
    "    * Output layers – size = output size (e.g. # classes)\n",
    "- Topology\n",
    "    * Full connected layers (one-way connections, recurrent connections)\n",
    "\n",
    "Mechanism\n",
    "- Neuron activation\n",
    "    * Constant, step, linear, sigmoid\n",
    "- Cost & Loss function -> smooth cost function (depends on w & b)\n",
    "    * Difference between desired (D) and computed © output\n",
    "    * Quadratic cost (mean squared error)\n",
    "    > $\\frac{\\sum{|| D – C||^2}}{2n}$\n",
    "    * Cross-entropy\n",
    "    >  $-\\sum{\\frac{D ln C + ( 1 – D) ln(1 - C)}{n}}$ \n",
    "\n",
    "Learning algorithm \n",
    "- Perceptron rule\n",
    "- Delta rule (Simple/Stochastic Gradient Descent)\n",
    "\n",
    "\n",
    "\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "\n",
    "\n",
    "**Convolutional NNs**\n",
    "\n",
    "Main characteristics:\n",
    "- More layers\n",
    "- More nodes/layer\n",
    "\n",
    "Topology of connections\n",
    "- Regular NNs -> fully connected\n",
    "    * O(\\#inputs x \\#outputs)\n",
    "- Conv NNs -> partially connected\n",
    "    * connect each neuron to only a local region of the input volume\n",
    "    * O(\\#someInputs x \\#outputs)\n",
    "\n",
    " <img src=\"images\\anns.png\" alt=\"networks\" width=\"400\"/>\n",
    "\n",
    "\n",
    "Topology of layers\n",
    "- Regular NNs -> linear layers\n",
    "- Conv NNs -> 2D/3D layers (width, height, depth)\n",
    "\n",
    "<img src=\"images/cnn.png\" alt=\"conv networks\"/>"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "** Convolutional layer **\n",
    "\n",
    "Aim \n",
    "- learn data-specific kernels\n",
    "- perform a liniar  (see this [material](https://arxiv.org/pdf/1603.07285v1.pdf) for math explanations)\n",
    "\n",
    "Filters or Local receptive fields or Kernels\n",
    "- Content\n",
    "    * convolution (signal theory) vs. Cross-correlation \n",
    "    * a little (square/cube) window on the input pixels\n",
    "- How it works?\n",
    "    * slide the local receptive field across the entire input image\n",
    "- Size\n",
    "    * size of field / filter (F)\n",
    "    * Stride (S)\n",
    "- Learning process\n",
    "    * each hidden neuron has \n",
    "        - FxF shared weights connected to its local receptive field\n",
    "        - a shared bias\n",
    "        - an activation function\n",
    "    * each connection learns a weight\n",
    "    * the hidden neuron learns an overall bias as well\n",
    "    * all the neurons in the first hidden layer detect exactly the same feature (just at different locations in the input image) -> map from input to the first hidden layer = feature map / activation map\n",
    "\n",
    "How does it work?\n",
    "\n",
    "- Take an input I (example, instance, data) of various dimensions \n",
    "    * a signal -> 1D input (I_{length})\n",
    "    * a grayscale image -> 2D input (I_{Width} & I_{Height})\n",
    "    * an RGB image -> 3D input (I_{Width}, I_{Height} & I_{Depth} = 3) \n",
    "- Consider a set of filters (kernels) F_1, F_2, ..., F_{#filters}\n",
    "    * A filter must have the same \\# dimensions as the input\n",
    "        - A signal -> 1D filter \n",
    "        > F_{length} << I_{length}\n",
    "        - a grayscale image -> 2D filter \n",
    "        > F_{width} << I_{width} & F_{height} << I_{height}\n",
    "        - an RGB image -> 3D filter\n",
    "        > F_{width} << I_{width} & F_{height} << I_{height} &  F_{depth} = I_{Depth} = 3\n",
    "- Apply each filter over the input\n",
    "    * Overlap filter over a window of the input\n",
    "        - Stride\n",
    "        - Padding \n",
    "    * Multiply the filter and the window\n",
    "    * Store the results in an activation map\n",
    "        - \\# activation maps = # filters\n",
    "- Activate all the elements of each activation map\n",
    "    * ReLU or other activation function\n",
    "\n",
    "<img src=\"images\\filter1.png\" alt=\"filters\" width=\"400\"/>\n",
    "\n",
    "     \n",
    "<img src=\"images\\filter2.png\" alt=\"filters\" width=\"400\"/>\n",
    "\n",
    "\n",
    "<img src=\"images\\filter3.png\" alt=\"filters\" width=\"400\"/>\n",
    "\n",
    "\n",
    "\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "**Hyperparameters**\n",
    "\n",
    "- input volume size N (L or WI & HI or WI & HI & DI)\n",
    "- size of zero-padding of input volume P (PL or PW & PH or PW & PH & PD)\n",
    "- the receptive field size (filter size) F (FL, FW & FH, FW & FH & FD) \n",
    "- stride of the convolutional layer S (SL, SW & SH, SW & SH & SD)\n",
    "- \\# of filters (K)\n",
    "- depth of the output volume \n",
    "\n",
    "\\# neurons of an activation map =  (N + 2P − F)/S+1\n",
    "\n",
    "Output size (O or WO & HO or WO & HO & DO)\n",
    "- K * [(N + 2P − F)/S+1]\n",
    "\n",
    "N = L = 5, P = 1, \n",
    "- F = 3, S = 1\n",
    "- F = 3, S = 2\n",
    "\n",
    "<img src=\"images\\hyperparam.png\" alt=\"hyperparameters\" width=\"400\"/>\n",
    "\n",
    "<img src=\"images\\convComputing.png\" alt=\"convolution\" width=\"400\"/>\n",
    "\n",
    "<img src=\"images\\sliding.png\" alt=\"sliding\" width=\"400\"/>\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "**Convolutional layer** – typology \n",
    "\n",
    "- Classic convolution\n",
    "    \n",
    "    * one filter, D channels\n",
    "    \n",
    "    <img src=\"images/oneFilter.png\" alt=\"convolution\" width=\"600\"/>\n",
    "\n",
    "    * more filters (K), D channels\n",
    "\n",
    "    <img src=\"images/moreFilters.png\" alt=\"convolution\" width=\"600\"/>\n",
    "\n",
    "- Transposed convolution (deconvolution)\n",
    "\n",
    "    * See [article](https://arxiv.org/pdf/1603.07285.pdf)\n",
    "    \n",
    "    * Up-sampling - How? <img src=\"images/transposedConv.gif\" alt=\"convolution\" width=\"200\"/>\n",
    "\n",
    "        - $ ImgLarge * F = ImgSmall$\n",
    "    \n",
    "        - $ ImgLarge * F * F^T = ImgSmall* F^T $\n",
    "    \n",
    "        - $ ImgLarge * I = ImgSmall * F^T $\n",
    "    \n",
    "        - $ ImgLarge = ImgSmall * F^T $\n",
    "\n",
    "        \n",
    "\n",
    "- Dilated convolution (atrous convolution)\n",
    "\n",
    "    * see [link](https://arxiv.org/pdf/1511.07122.pdf)\n",
    "\n",
    "    <img src=\"images/dilatedConv.gif\" alt=\"convolution\" width=\"400\"/>\n",
    "\n",
    "\n",
    "- Spatial separable (depth-wise separable) convolution\n",
    "    \n",
    "    * Split the convolution into\n",
    "        \n",
    "        - A depthwise convolution <img src=\"images/depthWiseConv.png\" alt=\"convolution\" width=\"400\"/>\n",
    "\n",
    "        - A pointwise convolution \n",
    "\n",
    "        <img src=\"images/pointWiseConv1.png\" alt=\"convolution\" width=\"400\"/>\n",
    "\n",
    "        <img src=\"images/pointWiseConv2.png\" alt=\"convolution\" width=\"400\"/>   \n",
    "\n",
    "    * E.g. Sobel operator\n",
    "\n",
    "    <img src=\"images/stdVsDepthwiseConv.png\" alt=\"convolution\" width=\"400\"/>   \n",
    "\n",
    "    * standard versus spatial separable \n",
    "\n",
    " \n",
    "\n",
    "\n",
    "\n",
    "\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "| standard (classic) | | spatial separable |\n",
    "| :--- | :---: |:--- |\n",
    "| Image: $W_I \\times H_I \\times D_I = 12 \\times 12 \\times 3$ | | Image: $W_I \\times H_I \\times D_I = 12 \\times 12 \\times 3$ |\n",
    "| 1 filter: $F_w \\times F_H \\times F_D = 5 \\times 5 \\times 3$ | | 3 filters: $F_w \\times F_H \\times F_D = 5 \\times 5 \\times 1$ |\n",
    "| | | 1 filter $F'_W \\times F'_H \\times F'_D = 1 \\times 1 \\times 3$ | | \n",
    "| No padding: P = 0 | | No padding: P = 0 | \n",
    "| Stride 1: S = 1 | | Stride 1: S = 1 |\n",
    "| Output: $W_O \\times H_o \\times D_O = 8 \\times 8 \\times 1$ | | Output: $W_O \\times H_O \\times D_O = 8 \\times 8 \\times 256$ |\n",
    "| 1 * (5 * 5 * 3) * (8 * 8) = 4 800 | | 3 * (5 * 5) * (8 * 8) = 4 800 |\n",
    "| | | 1 * (1 * 1 * 3) * (8 * 8) = 192 |\n",
    "| => 4 800 ops. | | => 4 992 ops |\n",
    "|--------------------------------|---|--------------------------------|\n",
    "| Image: $W_I \\times H_I \\times D_I = 12 \\times 12 \\times 3$ | | Image: $W_I \\times H_I \\times D_I = 12 \\times 12 \\times 3$ |\n",
    "| 256 filters: $F_w \\times F_H \\times F_D = 5 \\times 5 \\times 3$ | | 3 filters: $F_w \\times F_H \\times F_D = 5 \\times 5 \\times 1$ |\n",
    "| | | 256 filters $F'_W \\times F'_H \\times F'_D = 1 \\times 1 \\times 3$ | \n",
    "| No padding: P = 0 | | No padding: P = 0 | \n",
    "| Stride 1: S = 1 | | Stride 1: S = 1 |\n",
    "| Output: $W_O \\times H_o \\times D_O = 8 \\times 8 \\times 256$ | | Output: $W_O \\times H_O \\times D_O = 8 \\times 8 \\times 256$ |\n",
    "| 256 * (5 * 5 * 3) * (8 * 8) =  1 228 800 | | 3 * (5 * 5) * (8 * 8) = 4800 |\n",
    "| | | 256 * (1 * 1 * 3) * (8 * 8) = 49 152 |\n",
    "| => 1 228 800 ops. | | => 53 952 ops |\n",
    "\n",
    "\n",
    "- Grouped convolutions\n",
    "    \n",
    "    * See [article](https://arxiv.org/pdf/1605.06489.pdf)\n",
    "    \n",
    "    * Efficient training (More GPUs) => model parallelisation\n",
    "    \n",
    "    * Fewer parameters \n",
    "    \n",
    "    * Better representations\n",
    "    \n",
    "<img src=\"images/groupConv1.png\" alt=\"convolution\" width=\"400\"/>\n",
    "\n",
    "   \n",
    "<img src=\"images/groupConv2.png\" alt=\"convolution\" width=\"400\"/>\n",
    "\n",
    "\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Note:\n",
    "- Images taken from Andrej Karpathy’s lectures about Conv NNs"
   ]
  }
 ]
}